{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiwari-arpit/nlp/blob/main/HindiNER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9HIF4V5X1Ko"
      },
      "source": [
        "# Libraries (Setup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egk4QWEYbQ0p"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "#!pip install -U transformers\n",
        "!pip install -U accelerate\n",
        "!pip install seqeval\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6DdVHCVb6zl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVsRgiO4YRiw"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEGzXn1BbWbB"
      },
      "outputs": [],
      "source": [
        "# Dataset source: https://huggingface.co/datasets/ai4bharat/naamapadam\n",
        "\n",
        "from datasets import load_dataset\n",
        "lang = 'hi'\n",
        "hindi_data = load_dataset('ai4bharat/naamapadam',lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrSHmbBBZD53"
      },
      "outputs": [],
      "source": [
        "hindi_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjxkdElyboMP"
      },
      "outputs": [],
      "source": [
        "hindi_data['train'].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H0inthDcVKg"
      },
      "outputs": [],
      "source": [
        "tags = hindi_data['train'].features['ner_tags'].feature\n",
        "\n",
        "def create_tag_name(batch):\n",
        "  tag_name = {'ner_tags_str': [ tags.int2str(idx) for idx in batch['ner_tags']]}\n",
        "  return tag_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e2O9dMQpz8H"
      },
      "outputs": [],
      "source": [
        "hindi_data = hindi_data.map(create_tag_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVnp_afEqLlk"
      },
      "outputs": [],
      "source": [
        "hindi_data['train'].to_pandas().iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUg-CQhfbFNT"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f5mXgFpZe3s"
      },
      "source": [
        "**Load Pre-trained Model for Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odCa7kjIqvl6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# model_checkpoint = 'distilbert-base-cased'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"arpit-tiwari/distilbert-finetuned-hindi-ner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOxG7SfWZk1U"
      },
      "source": [
        "**Tokenize all texts and align the labels with them**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJZs9G5rrlrU"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "  new_labels = []\n",
        "  current_word=None\n",
        "  for word_id in word_ids:\n",
        "    if word_id != current_word:\n",
        "      current_word = word_id\n",
        "      label = -100 if word_id is None else labels[word_id]\n",
        "      new_labels.append(label)\n",
        "\n",
        "    elif word_id is None:\n",
        "      new_labels.append(-100)\n",
        "\n",
        "    else:\n",
        "      label = labels[word_id]\n",
        "\n",
        "      if label%2==1:\n",
        "        label = label + 1\n",
        "      new_labels.append(label)\n",
        "\n",
        "  return new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya7vAeJqsaUe"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = tokenizer(examples['tokens'],truncation=True,is_split_into_words=True)\n",
        "  all_labels = examples['ner_tags']\n",
        "  new_labels = []\n",
        "  for i, labels in enumerate(all_labels):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    new_labels.append(align_labels_with_tokens(labels,word_ids))\n",
        "\n",
        "  tokenized_inputs['labels'] = new_labels\n",
        "  return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReKkZH6rs0w9"
      },
      "outputs": [],
      "source": [
        "tokenized_data = hindi_data.map(tokenize_and_align_labels,batched=True,remove_columns=hindi_data['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCkXqMrRtKPr"
      },
      "outputs": [],
      "source": [
        "tokenized_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG23yi67Zupg"
      },
      "source": [
        "**Create Data Collator and Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxpLV7KUtNpQ"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_colator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Fx9wuYktVG2"
      },
      "outputs": [],
      "source": [
        "batch = data_colator([tokenized_data['train'][i] for i in range(2)])\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMeiwWHktmy7"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "metric = evaluate.load('seqeval')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGUsK1m_tuRc"
      },
      "outputs": [],
      "source": [
        "ner_feature = hindi_data['train'].features['ner_tags']\n",
        "label_names = ner_feature.feature.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn7kGBA7uk1b"
      },
      "outputs": [],
      "source": [
        "id2label = {i:label for i, label in enumerate(label_names)}\n",
        "label2id = {label:i for i, label in enumerate(label_names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-ZchnEdun3D"
      },
      "outputs": [],
      "source": [
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8lVpV31ugtl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  logits, labels = eval_preds\n",
        "\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "  true_labels = [[label_names[l] for l in label if l!=-100] for label in labels]\n",
        "\n",
        "  true_predictions = [[label_names[p] for p,l in zip(prediction, label) if l!=-100]\n",
        "                      for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "  all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "  return {\"precision\": all_metrics['overall_precision'],\n",
        "          \"recall\": all_metrics['overall_recall'],\n",
        "          \"f1\": all_metrics['overall_f1'],\n",
        "          \"accuracy\": all_metrics['overall_accuracy']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KJAUYXkaIP8"
      },
      "source": [
        "**Load Pre-trained Model for Token Classifiaction.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxtlvCJMuq4W"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "# model = AutoModelForTokenClassification.from_pretrained(\n",
        "#     model_checkpoint,\n",
        "#     id2label=id2label,\n",
        "#     label2id=label2id,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDNIH7Snu03j"
      },
      "outputs": [],
      "source": [
        "model.config.num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOTkkM74aMMx"
      },
      "source": [
        "**Set Training Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUq5wTCUTARV"
      },
      "outputs": [],
      "source": [
        "# Training on 50% data for 1 epoch\n",
        "#from sklearn.model_selection import train_test_split\n",
        "train_size = 0.5\n",
        "train_dataset = tokenized_data[\"train\"]\n",
        "\n",
        "train_dataset = train_dataset.select(range(700000,800000))\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi-09DeRu7db"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(output_dir = \"./distilbert-finetuned-hindi_ner\",\n",
        "                         evaluation_strategy = \"epoch\",\n",
        "                         save_strategy=\"epoch\",\n",
        "                         learning_rate = 2e-5,\n",
        "                         num_train_epochs=3,\n",
        "                         weight_decay=0.01)\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"./distilbert-finetuned-hindi__ner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2VzEtRiaTYm"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qC8w22avRag",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model = model,\n",
        "                  args = args,\n",
        "                  train_dataset = train_dataset,\n",
        "                  eval_dataset = tokenized_data['test'],\n",
        "                  data_collator = data_colator,\n",
        "                  compute_metrics = compute_metrics,\n",
        "                  tokenizer = tokenizer)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./distilbert-finetuned-hindi__ner\")"
      ],
      "metadata": {
        "id": "cOJbQ10KYt4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./distilbert-finetuned-hindi__ner')\n",
        "tokenizer.save_pretrained('./distilbert-finetuned-hindi__ner')"
      ],
      "metadata": {
        "id": "iGfrfMA_YyFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"./distilbert-finetuned-hindi__ner\"\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "36t9Z9VZY42C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "vZyM11IQY8hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, HfFolder\n",
        "\n",
        "model_name = \"./distilbert-finetuned-hindi__ner\"\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_folder(folder_path=model_name, path_in_repo=\"\", repo_id=\"arpit-tiwari/distilbert-finetuned-hindi-ner\", repo_type=\"model\")"
      ],
      "metadata": {
        "id": "HdlwE1EBZFi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"token-classification\", model=\"./distilbert-finetuned-hindi__ner\",aggregation_strategy=\"simple\")\n",
        "pipe((\"इटली की पीएम जॉर्जिया मेलोनी ने पूरी दुनिया के लेफ्टिस्ट लीडर्स को पाखंडी बताया है। उन्होंने कहा कि दुनियाभर में मोदी, ट्रम्प और मेरे जैसे दक्षिणपंथी नेताओं के उभरने से सारे लेफ्टिस्ट नेता परेशान हो गए हैं|\"))"
      ],
      "metadata": {
        "id": "PM-7d4uiYNEz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}